{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, \\\n",
    "'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, \\\n",
    "'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, \\\n",
    "'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, \\\n",
    "'id':str, 'sqft_lot':int, 'view':int}\n",
    "data_house = pd.read_csv('C://Users//xyzs//Machine Learning//Week 1//kc_house_train_data.csv',dtype = dtype_dict)\n",
    "data_house1 = pd.read_csv('C://Users//xyzs//Machine Learning//Week 1//kc_house_test_data.csv',dtype = dtype_dict)\n",
    "\n",
    "\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)\n",
    "sales = sales.sort_values(['sqft_living','price'])\n",
    "\n",
    "def get_residual_sum_of_squares(input_feature, output, intercept,slope):\n",
    "    RSS_R = (output - np.dot(input_feature, slope) - intercept)\n",
    "    RSS_L = np.transpose(RSS_R)\n",
    "    RSS = np.dot(RSS_L,RSS_R)\n",
    "    return(RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2_small_penalty = 1.5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynomial_dataframe(feature, degree): # feature is pandas.Series type\n",
    "    # assume that degree >= 1\n",
    "    # initialize the dataframe:\n",
    "    poly_dataframe = pd.DataFrame()\n",
    "    # and set poly_dataframe['power_1'] equal to the passed feature\n",
    "    poly_dataframe['power_1'] = feature\n",
    "    # first check if degree > 1\n",
    "    if degree > 1:\n",
    "        # then loop over the remaining degrees:\n",
    "        for power in range(2, degree+1):\n",
    "            # first we'll give the column a name:\n",
    "            name = 'power_' + str(power)\n",
    "            # assign poly_dataframe[name] to be feature^power; use apply(*)\n",
    "            poly_dataframe[name] = feature.apply(lambda x: x**power)\n",
    "    return poly_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.24873306e+02,  -4.77376011e-02,   3.01446238e-05,\n",
       "        -2.44419942e-09,  -1.94153675e-13,   8.54085685e-18,\n",
       "         1.51142121e-21,   8.27979094e-26,   6.52603100e-31,\n",
       "        -3.27895017e-34,  -3.87962315e-38,  -2.72437650e-42,\n",
       "        -1.07790800e-46,   3.78242694e-51,   1.39790296e-54])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "poly15_data = polynomial_dataframe(sales['sqft_living'], 15) # use equivalent of `polynomial_sframe`\n",
    "model = linear_model.Ridge(alpha=l2_small_penalty, normalize=True)\n",
    "result = model.fit(poly15_data, sales['price'])\n",
    "result.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtype_dict same as above\n",
    "set_1 = pd.read_csv('wk3_kc_house_set_1_data.csv', dtype=dtype_dict)\n",
    "set_2 = pd.read_csv('wk3_kc_house_set_2_data.csv', dtype=dtype_dict)\n",
    "set_3 = pd.read_csv('wk3_kc_house_set_3_data.csv', dtype=dtype_dict)\n",
    "set_4 = pd.read_csv('wk3_kc_house_set_4_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32806802958\n",
      "2.09756902778\n",
      "2.28906258119\n",
      "2.08596194092\n"
     ]
    }
   ],
   "source": [
    "l2_small_penalty=1e-9\n",
    "l2_large_penalty=1.23e2\n",
    "for i in range(1,5):\n",
    "    set_x = eval('set_' + str(i))\n",
    "    poly15_data = polynomial_dataframe(set_x['sqft_living'], 15) # use equivalent of `polynomial_sframe`\n",
    "    model = linear_model.Ridge(alpha=l2_large_penalty, normalize=True)\n",
    "    result = model.fit(poly15_data, set_x['price'])\n",
    "    print(result.coef_[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_valid_shuffled = pd.read_csv('wk3_kc_house_train_valid_shuffled.csv', dtype=dtype_dict)\n",
    "test = pd.read_csv('wk3_kc_house_test_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.0, 1938.6)\n",
      "1 (1939.6, 3878.2)\n",
      "2 (3879.2, 5817.8)\n",
      "3 (5818.8, 7757.4)\n",
      "4 (7758.4, 9697.0)\n",
      "5 (9698.0, 11636.6)\n",
      "6 (11637.6, 13576.2)\n",
      "7 (13577.2, 15515.8)\n",
      "8 (15516.8, 17455.4)\n",
      "9 (17456.4, 19395.0)\n"
     ]
    }
   ],
   "source": [
    "n = len(train_valid_shuffled)\n",
    "k = 10 # 10-fold cross-validation\n",
    "\n",
    "for i in range(k):\n",
    "    start = (n*i)/k\n",
    "    end = (n*(i+1))/k-1\n",
    "    print (i, (start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_valid_shuffled[0:10] # select rows 0 to 9\n",
    "#start = (n*i)//10\n",
    "#end = (n*(i+1))//10\n",
    "#train_valid_shuffled[start:end+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(k, l2_penalty, data, output):\n",
    "    n = len(data)\n",
    "    k = 10 # 10-fold cross-validation\n",
    "    avg_valid_error = 0\n",
    "    for i in range(k):\n",
    "        start = (n*i)//k\n",
    "        end = (n*(i+1))//k-1\n",
    "        data_valid = data[start:end+1]\n",
    "        data_train = data[0:start].append(data[end+1:n])\n",
    "        poly15_data = polynomial_dataframe(data_train['sqft_living'], 15) # use equivalent of `polynomial_sframe`\n",
    "        model = linear_model.Ridge(alpha=l2_penalty, normalize=True)\n",
    "        result = model.fit(poly15_data, data_train['price'])\n",
    "        poly15_valid_data = polynomial_dataframe(data_valid['sqft_living'],15)\n",
    "        avg_valid_error += get_residual_sum_of_squares(poly15_valid_data, data_valid['price'], result.intercept_,result.coef_)\n",
    "    avg_valid_error = avg_valid_error/10\n",
    "    print(result.intercept_)\n",
    "    print(avg_valid_error)\n",
    "    print(l2_penalty)\n",
    "    return avg_valid_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537954.868189\n",
      "2.64977361037e+14\n",
      "1000.0\n",
      "1000.0\n",
      "0\n",
      "538612.921296\n",
      "2.65692935858e+14\n",
      "3162.27766017\n",
      "3162.27766017\n",
      "1\n",
      "538821.682334\n",
      "2.65924368957e+14\n",
      "10000.0\n",
      "10000.0\n",
      "2\n",
      "538887.765405\n",
      "2.65998081509e+14\n",
      "31622.7766017\n",
      "31622.7766017\n",
      "3\n",
      "538908.669423\n",
      "2.66021444554e+14\n",
      "100000.0\n",
      "100000.0\n",
      "4\n",
      "538915.280526\n",
      "2.66028837919e+14\n",
      "316227.766017\n",
      "316227.766017\n",
      "5\n",
      "538917.371208\n",
      "2.66031176438e+14\n",
      "1000000.0\n",
      "1000000.0\n",
      "6\n",
      "538918.032346\n",
      "2.66031915997e+14\n",
      "3162277.66017\n",
      "3162277.66017\n",
      "7\n",
      "538918.241417\n",
      "2.66032149871e+14\n",
      "10000000.0\n",
      "10000000.0\n",
      "8\n",
      "538918.307531\n",
      "2.66032223829e+14\n",
      "31622776.6017\n",
      "31622776.6017\n",
      "9\n",
      "538918.328438\n",
      "2.66032247216e+14\n",
      "100000000.0\n",
      "100000000.0\n",
      "10\n",
      "538918.33505\n",
      "2.66032254612e+14\n",
      "316227766.017\n",
      "316227766.017\n",
      "11\n",
      "538918.33714\n",
      "2.66032256951e+14\n",
      "1000000000.0\n",
      "1000000000.0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "l2_penalty = np.logspace(3, 9, num=13)\n",
    "k = 10\n",
    "data = train_valid_shuffled\n",
    "output = 1\n",
    "for i in range(13):\n",
    "    k_fold_cross_validation(k, l2_penalty[i], data, output)\n",
    "    print(l2_penalty[i])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.83856861224e+14\n"
     ]
    }
   ],
   "source": [
    "l2_penalty = 1000\n",
    "k = 10\n",
    "data = train_valid_shuffled\n",
    "poly15_data = polynomial_dataframe(data['sqft_living'], 15) # use equivalent of `polynomial_sframe`\n",
    "model = linear_model.Ridge(alpha=l2_penalty, normalize=True)\n",
    "result = model.fit(poly15_data, data['price'])\n",
    "poly15_valid_data = polynomial_dataframe(test['sqft_living'],15)\n",
    "avg_valid_error = get_residual_sum_of_squares(poly15_valid_data, test['price'], result.intercept_,result.coef_)\n",
    "print(avg_valid_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ridge regression via gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_house = pd.read_csv('kc_house_train_data.csv',dtype = dtype_dict)\n",
    "data_house1 = pd.read_csv('kc_house_test_data.csv',dtype = dtype_dict)\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.55328923356e+13\n",
      "-4.55328923355e+13\n",
      "\n",
      "-18029479492.0\n",
      "-18029479492.0\n"
     ]
    }
   ],
   "source": [
    "sales1 = data_house.copy()\n",
    "sales1['constant'] = 1\n",
    "example_features = np.array(sales1[['constant','sqft_living']])\n",
    "example_output = np.array(sales1['price'])\n",
    "\n",
    "my_weights = np.array([1., 10.])\n",
    "test_predictions = predict_outcome(example_features, my_weights)\n",
    "errors = test_predictions - example_output # prediction errors\n",
    "\n",
    "# next two lines should print the same values\n",
    "print (feature_derivative_ridge(errors, example_features[:,1], my_weights[1], 1, False))\n",
    "print (np.sum(errors*example_features[:,1])*2+20.)\n",
    "print ('')\n",
    "\n",
    "# next two lines should print the same values\n",
    "print (feature_derivative_ridge(errors, example_features[:,0], my_weights[0], 1, True))\n",
    "print (np.sum(errors)*2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_outcome(feature_matrix, weights):\n",
    "    predictions = np.dot(feature_matrix,weights)\n",
    "    return(predictions)\n",
    "\n",
    "def feature_derivative(errors, feature):\n",
    "    derivative = 2*np.dot(np.transpose(feature),errors)\n",
    "    #print(derivative)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative_ridge(errors, feature, weight, l2_penalty, feature_is_constant):\n",
    "    if feature_is_constant == True:\n",
    "        derivative = 2*np.dot(np.transpose(feature),errors)\n",
    "    else:\n",
    "        #print(1)\n",
    "        derivative = 2*np.dot(np.transpose(feature),errors) - 2*l2_penalty*weight\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, l2_penalty, max_iterations=100):\n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    iteration = 0\n",
    "    while iteration <= max_iterations:\n",
    "        #while not reached maximum number of iterations:\n",
    "        # compute the predictions using your predict_output() function\n",
    "        predictions = predict_outcome(feature_matrix, weights)\n",
    "        #print(np.shape(predictions))\n",
    "        #print(predictions)\n",
    "        # compute the errors as predictions - output\n",
    "        errors = output - predictions\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:,i] is the feature column associated with weights[i]\n",
    "            if i == 0:\n",
    "                derivative = feature_derivative_ridge(errors,feature_matrix[:,i],weights[i], l2_penalty, True)\n",
    "                #derivative = feature_derivative(errors, feature_matrix[:,i])\n",
    "            # compute the derivative for weight[i].\n",
    "            else:\n",
    "            #(Remember: when i=0, you are computing the derivative of the constant!)\n",
    "                derivative = feature_derivative_ridge(errors,feature_matrix[:,i],weights[i], l2_penalty, False)\n",
    "                #derivative = feature_derivative(errors, feature_matrix[:,i])\n",
    "            # subtract the step size times the derivative from the current weight  \n",
    "            weights[i] = weights[i] + step_size*derivative\n",
    "        iteration += 1\n",
    "        #print(l2_penalty)\n",
    "    return (weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.63382329e-01   2.63024369e+02]\n",
      "[   9.77704731  124.57217382]\n"
     ]
    }
   ],
   "source": [
    "step_size = 1e-12\n",
    "max_iterations = 1000\n",
    "initial_weights = [0.,0.]\n",
    "simple_weights_0_penalty = 0\n",
    "simple_weights_high_penalty = 1e11\n",
    "feature_matrix = np.array(sales1[['constant','sqft_living']])\n",
    "output = np.array(sales1['price'])\n",
    "\n",
    "weights_0_penalty = ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, simple_weights_0_penalty, max_iterations)\n",
    "weights_high_penalty = ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, simple_weights_high_penalty, max_iterations)\n",
    "print(weights_0_penalty)\n",
    "print(weights_high_penalty)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the RSS using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7572278145244526"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix = np.array(data_house1['sqft_living'])\n",
    "output = np.array(data_house1['price'])\n",
    "get_residual_sum_of_squares(feature_matrix, output, weights_0_penalty[0],weights_0_penalty[1])/1e14\n",
    "#weights_0_penalty\n",
    "#get_residual_sum_of_squares(input_feature, output, intercept,slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqft_living, sqft_living15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  -0.35780714  243.05572642   22.41312485]\n",
      "[  6.74968592  91.48927275  78.43658676]\n"
     ]
    }
   ],
   "source": [
    "model_features = np.array(sales1[['constant','sqft_living', 'sqft_living15']])\n",
    "my_output = np.array(sales1['price'])\n",
    "#(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "#(test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "initial_weights = [0.,0.,0.]\n",
    "step_size = 1e-12\n",
    "max_iterations = 1000\n",
    "l2_penalty=1e11\n",
    "##################################################\n",
    "simple_weights_0_penalty = 0\n",
    "simple_weights_high_penalty = 1e11\n",
    "##################################################\n",
    "weights_0_penalty = ridge_regression_gradient_descent(model_features, my_output, initial_weights, step_size, simple_weights_0_penalty, max_iterations)\n",
    "print(weights_0_penalty)\n",
    "weights_high_penalty = ridge_regression_gradient_descent(model_features, my_output, initial_weights, step_size, simple_weights_high_penalty, max_iterations)\n",
    "print(weights_high_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the RSS using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.523784126261825"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_feature = data_house1.copy()\n",
    "model_test_feature['constant'] = 1\n",
    "model_test_feature1 =np.array(model_test_feature[['constant','sqft_living','sqft_living15']])\n",
    "my_output = np.array(model_test_feature['price'])\n",
    "\n",
    "model_test_feature_rss = np.array(model_test_feature[['sqft_living','sqft_living15']])\n",
    "weights_high_penalty = ridge_regression_gradient_descent(model_test_feature1, my_output, initial_weights, step_size, simple_weights_high_penalty, max_iterations)\n",
    "get_residual_sum_of_squares(model_test_feature_rss, my_output, weights_high_penalty[0],weights_high_penalty[1:])/1e14\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first house in test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764978.122324\n",
      "437754.39996\n"
     ]
    }
   ],
   "source": [
    "############################ 0 penalty\n",
    "temp = np.array(data_house1[['sqft_living','sqft_living15']])[1]\n",
    "penalty_0 = np.dot(temp,np.transpose(weights_0_penalty[1:])) + weights_0_penalty[0]\n",
    "print(penalty_0)\n",
    "#data_house1['price'][0]\n",
    "############################ high penalty\n",
    "penalty_high = np.dot(temp,np.transpose(weights_high_penalty[1:])) + weights_high_penalty[0]\n",
    "print(penalty_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540088.141761 [  0.00000000e+00   2.80623568e-09]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100000000000.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly15_data = np.array(sales1[['constant','sqft_living']])# use equivalent of `polynomial_sframe`\n",
    "model = linear_model.Ridge(alpha=simple_weights_high_penalty, normalize=True)\n",
    "result = model.fit(poly15_data, np.array(sales1['price']))\n",
    "print(result.intercept_,result.coef_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const     -43580.743094\n",
       "power_1      280.623568\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_data = polynomial_dataframe(sales1['sqft_living'], 1)\n",
    "poly_data = sm.add_constant(poly_data)\n",
    "model = sm.OLS(sales1['price'],poly_data)\n",
    "results = model.fit()\n",
    "weights = results.params\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    derivative = 2*np.dot(np.transpose(feature),errors)\n",
    "    #print(derivative)\n",
    "    return(derivative)\n",
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False\n",
    "    weights = np.array(initial_weights)\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights:\n",
    "        predictions = predict_outcome(feature_matrix, weights)\n",
    "        #print('predictions:',predictions)\n",
    "        #print(len(predictions))\n",
    "        # compute the errors as predictions - output:\n",
    "        errors = output - predictions\n",
    "        #print(len(errors))\n",
    "        \n",
    "        gradient_sum_squares = 0 # initialize the gradient\n",
    "        # while not converged, update each weight individually:\n",
    "        for i in range(len(weights)):\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            #print(i)\n",
    "            #print('error:',errors[i])\n",
    "            #print(feature_matrix[:,i])\n",
    "            derivative = feature_derivative(errors,feature_matrix[:,i])\n",
    "            #print(derivative)\n",
    "            # add the squared derivative to the gradient magnitude\n",
    "            gradient_sum_squares = gradient_sum_squares + derivative**2\n",
    "            # update the weight based on step size and derivative:\n",
    "            weights[i] = weights[i] + step_size*derivative\n",
    "        gradient_magnitude = np.sqrt(gradient_sum_squares)\n",
    "        #print(gradient_magnitude)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-46999.88187784    281.99922246]\n"
     ]
    }
   ],
   "source": [
    "feature_matrix = np.array(sales1[['constant','sqft_living']])\n",
    "output = np.array(sales1['price'])\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7\n",
    "simple_weights = regression_gradient_descent(feature_matrix, output,initial_weights, step_size,tolerance)\n",
    "print(simple_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20000164ba8>,\n",
       " <matplotlib.lines.Line2D at 0x2000017aa90>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEACAYAAABoJ6s/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYRhZ4/8DX8YJw7BCPdQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20000255ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(feature_matrix,output,'k.')\n",
    "plt.plot(feature_matrix,predict_outcome(feature_matrix, weights_0_penalty),'b-')\n",
    "plt.plot(feature_matrix,predict_outcome(feature_matrix, weights_high_penalty),'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fcbc011fe751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfeature_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sqft_living'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sqft_living15'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msimple_weights_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-9f1cfd645f0d>\u001b[0m in \u001b[0;36mregression_gradient_descent\u001b[0;34m(feature_matrix, output, initial_weights, step_size, tolerance)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#print('error:',errors[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m#print(feature_matrix[:,i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mderivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m#print(derivative)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# add the squared derivative to the gradient magnitude\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-9f1cfd645f0d>\u001b[0m in \u001b[0;36mfeature_derivative\u001b[0;34m(errors, feature)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mderivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(derivative)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mderivative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mregression_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_features = sales1[['constant','sqft_living', 'sqft_living15']]\n",
    "my_output =sales1['price']\n",
    "#(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "#(test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "step_size = 1e-12\n",
    "max_iterations = 1000\n",
    "initial_weights = [0.,0.,0.]\n",
    "simple_weights_0_penalty = 0\n",
    "simple_weights_high_penalty = 1e11\n",
    "feature_matrix = np.array(sales1[['constant','sqft_living','sqft_living15']])\n",
    "output = np.array(sales1['price'])\n",
    "simple_weights_two = ridge_regression_gradient_descent(feature_matrix, output, initial_weights, step_size, simple_weights_high_penalty, max_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simple_weights_two"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
